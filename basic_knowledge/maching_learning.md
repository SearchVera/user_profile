**神经网络**

1. [梯度更新算法-owlqn](http://www.bigbear2017.com/blog/2016/06/07/owl-qnsuan-fa-jie-shao/)  
2. [梯度更新算法-Momentum,AdaGrad,RMSProp](https://blog.csdn.net/u014595019/article/details/52989301)
3. [激活函数+损失函数](https://www.cnblogs.com/pinard/p/6437495.html)

---

**GBDT, xgboost**
1. [GBDT总结](https://my.oschina.net/SearchVera/blog/1591457)
2. [xgboost-公式推导](https://www.zybuluo.com/yxd/note/611571)
3. [xgboost-与GBDT区别](https://www.jianshu.com/p/af1fbcd6058d) 
4. [xgboost-参数调优](https://blog.csdn.net/u010657489/article/details/51952785)
5. [xgboost-运行方法](https://www.jianshu.com/p/7e0e2d66b3d4)
6. [xgboost-缺失值处理](https://www.zhihu.com/question/34867991) 

---

**Logistic Regression** 
1. [LR-原理](https://blog.csdn.net/cyh_24/article/details/50359055)
2. [LR-和softmax关系](http://www.cnblogs.com/maybe2030/p/5678387.html)
2. [LR-和朴素贝叶斯的区别](https://blog.csdn.net/chlele0105/article/details/38922551)
