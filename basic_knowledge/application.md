**激活函数**
1. [常用激活函数](https://blog.csdn.net/cyh_24/article/details/50593400)
2. [激活函数作用](https://mp.weixin.qq.com/s/ADnhQT7yMU3p9WZs7xuHHQ)

**衡量指标**
1. [ROC, AUC](https://www.jianshu.com/p/c61ae11cc5f6)
2. [多分类AUC计算](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)
3. [概率校准-calibration](http://scikit-learn.org/stable/modules/calibration.html#)
4. [pearson相关系数](https://blog.csdn.net/wsywl/article/details/5727327)
5. [r2-决定系数](http://blog.sina.com.cn/s/blog_6aaea1760101oqbk.html)

**特征选择**
1. [特征工程](http://www.cnblogs.com/jasonfreak/p/5448385.html)
2. [特征选择-卡方检验](https://www.jianshu.com/p/b670b2a23187) 
3. [特征选择-信息增益](https://www.jianshu.com/p/9bbe71750547)
4. [特征选择-IV](https://blog.csdn.net/kevin7658/article/details/50780391)

**正则化**
1. [L1,L2范数](https://blog.csdn.net/zouxy09/article/details/24971995)
2. [L1,L2范数效果解释](https://blog.csdn.net/jinping_shi/article/details/52433975)

**防止过拟合**
1. 使用简单的模型 
2. 降维 
3. 正则化 
4. 增加样本
4. 算法本身（svm松弛变量，决策树剪枝，神经网络dropout,early stop）

**局部最小值**
1. [跳出局部最小值](https://blog.csdn.net/touch_dream/article/details/70142482)

**归一化原因**
1. 过大或过小的数值可能导致计算浮点的上溢或下溢
2. 不同的数值范围导致不同属性对模型的重要性不同，对优化造成困难，训练时间变长
3. 机器学习常用方法（正则）都假设属性取值在以0为均值的附近

**离散化**
1. [连续特征离散化优势](https://www.zhihu.com/question/31989952)

**梯度消失、爆炸**
1. [梯度消失，爆炸解决办法](https://blog.csdn.net/qq_25737169/article/details/78847691) 

**并行计算**
1. [分布式训练神经网络](https://blog.csdn.net/heyc861221/article/details/80125556)

**规则引擎**
1. 多模式匹配：dictmatch算法
2. 单模式匹配：[bm(Boyer-Moore)算法](http://www.cnblogs.com/lanxuezaipiao/p/3452579.html)
3. 数据结构：[Trie树](https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/06.09.md)

**面试题**
1. [海量数据面试题](https://www.jianshu.com/p/8a8f84b97671)
